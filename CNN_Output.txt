Convolutional Layer: 2
input_shape = (64,64,3)

Epoch 1/25
8000/8000 [==============================] - 2862s 358ms/step - loss: 0.3942 - acc: 0.8139 - val_loss: 0.4826 - val_acc: 0.8117
Epoch 2/25
8000/8000 [==============================] - 2585s 323ms/step - loss: 0.1791 - acc: 0.9268 - val_loss: 0.7466 - val_acc: 0.7966
Epoch 3/25
8000/8000 [==============================] - 2565s 321ms/step - loss: 0.0950 - acc: 0.9642 - val_loss: 0.9294 - val_acc: 0.8059
Epoch 4/25
8000/8000 [==============================] - 2564s 321ms/step - loss: 0.0654 - acc: 0.9760 - val_loss: 0.9563 - val_acc: 0.7992
Epoch 5/25
8000/8000 [==============================] - 2554s 319ms/step - loss: 0.0497 - acc: 0.9823 - val_loss: 1.1332 - val_acc: 0.8030
Epoch 6/25
8000/8000 [==============================] - 2581s 323ms/step - loss: 0.0409 - acc: 0.9854 - val_loss: 1.2304 - val_acc: 0.7905
Epoch 7/25
8000/8000 [==============================] - 2560s 320ms/step - loss: 0.0353 - acc: 0.9878 - val_loss: 1.2888 - val_acc: 0.8023
Epoch 8/25
8000/8000 [==============================] - 2570s 321ms/step - loss: 0.0305 - acc: 0.9894 - val_loss: 1.2838 - val_acc: 0.8033
Epoch 9/25
8000/8000 [==============================] - 2577s 322ms/step - loss: 0.0269 - acc: 0.9909 - val_loss: 1.2904 - val_acc: 0.8025
Epoch 10/25
8000/8000 [==============================] - 2576s 322ms/step - loss: 0.0255 - acc: 0.9912 - val_loss: 1.4090 - val_acc: 0.8010
Epoch 11/25
8000/8000 [==============================] - 2593s 324ms/step - loss: 0.0225 - acc: 0.9923 - val_loss: 1.3287 - val_acc: 0.7967
Epoch 12/25
8000/8000 [==============================] - 2566s 321ms/step - loss: 0.0193 - acc: 0.9934 - val_loss: 1.3915 - val_acc: 0.8046
Epoch 13/25
8000/8000 [==============================] - 2585s 323ms/step - loss: 0.0188 - acc: 0.9936 - val_loss: 1.3924 - val_acc: 0.8231
Epoch 14/25
8000/8000 [==============================] - 2553s 319ms/step - loss: 0.0174 - acc: 0.9942 - val_loss: 1.3487 - val_acc: 0.8125
Epoch 15/25
8000/8000 [==============================] - 2567s 321ms/step - loss: 0.0165 - acc: 0.9944 - val_loss: 1.4243 - val_acc: 0.8005
Epoch 16/25
8000/8000 [==============================] - 2563s 320ms/step - loss: 0.0157 - acc: 0.9948 - val_loss: 1.5508 - val_acc: 0.7955
Epoch 17/25
8000/8000 [==============================] - 2564s 321ms/step - loss: 0.0147 - acc: 0.9950 - val_loss: 1.3605 - val_acc: 0.8134
Epoch 18/25
8000/8000 [==============================] - 2560s 320ms/step - loss: 0.0130 - acc: 0.9956 - val_loss: 1.4702 - val_acc: 0.8072
Epoch 19/25
8000/8000 [==============================] - 2554s 319ms/step - loss: 0.0134 - acc: 0.9955 - val_loss: 1.4444 - val_acc: 0.8121
Epoch 20/25
8000/8000 [==============================] - 2577s 322ms/step - loss: 0.0128 - acc: 0.9959 - val_loss: 1.3997 - val_acc: 0.8108
Epoch 21/25
8000/8000 [==============================] - 2566s 321ms/step - loss: 0.0116 - acc: 0.9961 - val_loss: 1.5157 - val_acc: 0.8060
Epoch 22/25
8000/8000 [==============================] - 2561s 320ms/step - loss: 0.0111 - acc: 0.9962 - val_loss: 1.5778 - val_acc: 0.8010
Epoch 23/25
8000/8000 [==============================] - 2558s 320ms/step - loss: 0.0108 - acc: 0.9966 - val_loss: 1.5495 - val_acc: 0.8220
Epoch 24/25
8000/8000 [==============================] - 2562s 320ms/step - loss: 0.0102 - acc: 0.9967 - val_loss: 1.5125 - val_acc: 0.8101
Epoch 25/25
8000/8000 [==============================] - 2574s 322ms/step - loss: 0.0099 - acc: 0.9968 - val_loss: 1.7113 - val_acc: 0.7899
Out[33]: <keras.callbacks.History at 0x8b3e896828>


=============================================================================================================

Convolutional Layer: 3
input_shape = (64,64,3)
Added Dropout for avoiding over fitting. Dropout rate = 0.5
With these changes acc of test set has being increased to 88%

Epoch 1/25
8000/8000 [==============================] - 9545s 1s/step - loss: 0.3518 - acc: 0.8357 - val_loss: 0.4302 - val_acc: 0.8380
Epoch 2/25
8000/8000 [==============================] - 9000s 1s/step - loss: 0.1481 - acc: 0.9411 - val_loss: 0.5079 - val_acc: 0.8665
Epoch 3/25
8000/8000 [==============================] - 9015s 1s/step - loss: 0.0976 - acc: 0.9628 - val_loss: 0.5513 - val_acc: 0.8683
Epoch 4/25
8000/8000 [==============================] - 9070s 1s/step - loss: 0.0765 - acc: 0.9715 - val_loss: 0.5463 - val_acc: 0.8756
Epoch 5/25
8000/8000 [==============================] - 9050s 1s/step - loss: 0.0647 - acc: 0.9766 - val_loss: 0.6900 - val_acc: 0.8701
Epoch 6/25
8000/8000 [==============================] - 9048s 1s/step - loss: 0.0565 - acc: 0.9796 - val_loss: 0.7432 - val_acc: 0.8675
Epoch 7/25
8000/8000 [==============================] - 9034s 1s/step - loss: 0.0505 - acc: 0.9817 - val_loss: 0.6103 - val_acc: 0.8790
Epoch 8/25
8000/8000 [==============================] - 9170s 1s/step - loss: 0.0487 - acc: 0.9827 - val_loss: 0.6945 - val_acc: 0.8805
Epoch 9/25
8000/8000 [==============================] - 9111s 1s/step - loss: 0.0438 - acc: 0.9844 - val_loss: 0.6677 - val_acc: 0.8816
Epoch 10/25
8000/8000 [==============================] - 9977s 1s/step - loss: 0.0415 - acc: 0.9852 - val_loss: 0.9554 - val_acc: 0.8590
Epoch 11/25
8000/8000 [==============================] - 9055s 1s/step - loss: 0.0392 - acc: 0.9861 - val_loss: 0.7593 - val_acc: 0.8770
Epoch 12/25
8000/8000 [==============================] - 9014s 1s/step - loss: 0.0390 - acc: 0.9864 - val_loss: 0.7527 - val_acc: 0.8704
Epoch 13/25
8000/8000 [==============================] - 9026s 1s/step - loss: 0.0367 - acc: 0.9876 - val_loss: 0.8026 - val_acc: 0.8865
Epoch 14/25
8000/8000 [==============================] - 9029s 1s/step - loss: 0.0381 - acc: 0.9872 - val_loss: 0.7944 - val_acc: 0.8765
Epoch 15/25
8000/8000 [==============================] - 9008s 1s/step - loss: 0.0364 - acc: 0.9876 - val_loss: 0.7669 - val_acc: 0.8835
Epoch 16/25
8000/8000 [==============================] - 9046s 1s/step - loss: 0.0362 - acc: 0.9878 - val_loss: 0.7740 - val_acc: 0.8824
Epoch 17/25
8000/8000 [==============================] - 9010s 1s/step - loss: 0.0361 - acc: 0.9877 - val_loss: 0.7770 - val_acc: 0.8817
Epoch 18/25
8000/8000 [==============================] - 9078s 1s/step - loss: 0.0378 - acc: 0.9878 - val_loss: 0.7341 - val_acc: 0.8795
Epoch 19/25
8000/8000 [==============================] - 9334s 1s/step - loss: 0.0358 - acc: 0.9879 - val_loss: 0.7116 - val_acc: 0.8835
Epoch 20/25
8000/8000 [==============================] - 9063s 1s/step - loss: 0.0353 - acc: 0.9888 - val_loss: 0.8071 - val_acc: 0.8818
Epoch 21/25
8000/8000 [==============================] - 9045s 1s/step - loss: 0.0369 - acc: 0.9880 - val_loss: 0.6420 - val_acc: 0.8909
Epoch 22/25
8000/8000 [==============================] - 9156s 1s/step - loss: 0.0390 - acc: 0.9880 - val_loss: 0.8051 - val_acc: 0.8851
Epoch 23/25
8000/8000 [==============================] - 9285s 1s/step - loss: 0.0379 - acc: 0.9877 - val_loss: 0.7952 - val_acc: 0.8879
Epoch 24/25
8000/8000 [==============================] - 9058s 1s/step - loss: 0.0391 - acc: 0.9881 - val_loss: 0.8397 - val_acc: 0.8805
Epoch 25/25
8000/8000 [==============================] - 9091s 1s/step - loss: 0.0417 - acc: 0.9871 - val_loss: 0.8861 - val_acc: 0.8840
Out[14]: <keras.callbacks.History at 0x55e544e128>

